.rs.is_tex_installed()
help(text)
plot(1:10, 1:10, main = "text(...) examples\n~~~~~~~~~~~~~~",
sub = "R is GNU ©, but not ® ...")
mtext("«Latin-1 accented chars»: éè øØ å<Å æ<Æ", side = 3)
points(c(6,2), c(2,1), pch = 3, cex = 4, col = "red")
text(6, 2, "the text is CENTERED around (x,y) = (6,2) by default",
cex = .8)
print.letter <- function(label="(a)",xy=c(0.1,0.925),...) {
tmp <- par("usr")
text.x <- tmp[1]+xy[1]*diff(tmp[1:2])
text.y <- tmp[3]+xy[2]*diff(tmp[3:4])
text(x=text.x, y=text.y, labels=label, ...)
}
print.letter(label="(a)", xy=c(0.05,0.95))
help(par)
help(dev.off)
help(theme)
library(ggplot2)
help(theme)
system_fonts()
names(pdfFonts())
names(jpegFonts())
install.packages("extrafont")
library(extrafont)
font_import()
library(ggplot2)
help(geom_text)
counts <- table(mtcars$gear)
barplot(counts, main="Car Distribution",
xlab="Number of Gears")
counts
install.packages('rredlist')
library(rredlist)
rl_use_iucn()
rl_common_names('Sphyrna amblyrhinchos')
install.packages("lattice")
install.packages("mcgv")
mtcars2
mtcars
mtcars2 <- mtcars
mtcars2$am <- factor(
mtcars$am, labels = c('automatic', 'manual')
)
ggplot(mtcars2, aes(hp, mpg, color = am)) +  geom_point() + stat_smooth(method = "gam", formula = y ~ s(x), size = 1) + theme(legend.position = 'bottom')
library(ggplot2)
ggplot(mtcars2, aes(hp, mpg, color = am)) +  geom_point() + stat_smooth(method = "gam", formula = y ~ s(x), size = 1) + theme(legend.position = 'bottom')
install.packages("rethinking")
install.packages("rethinker")
library(rethinker)
data(Howell1)
data(Howell)
install.packages("rstan")
install.packages(c("coda", "mvtnorm", "devtools"))
library(devtools)
devtools::install_github("rmclereath/rethinking")
devtools::install_github("rmcelreath/rethinking")
library(rethinking)
data(Howell1)
install.packages("loo")
library(rstan)
data(Howell1)
library(rethinking)
version()
R.version()
R.Version()
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
library(rstan)
library(devtools)
R.Version()
install.packages("devtools")
library(devtools)
library(loo)
pkgbuild::has_build_tools(debug = TRUE)
install.packages("Rtools")
install.packages("rtools")
devtools::install_github("rmclereath/rethinking")
devtools::install_github("rmcelreath/rethinking")
install.packages(c("coda", "mvtnorm", "devtools"))
library(devtools)
library(rethinking)
library(rstan)
install.packages("devtools")
library(devtools)
remove.packages("devtools")
install.packages("devtools")
library(devtools)
library(devtools) build_github_devtools()
library(rstan)
library(loo)
library(devtools)
install.packages(c("BH", "cli", "colorspace", "crul", "curl", "data.table", "dplyr", "evaluate", "fansi", "ggthemes", "gplots", "hunspell", "hutils", "jsonlite", "knitr", "markdown", "packrat", "pillar", "purrr", "R6", "Rcpp", "readr", "RJSONIO", "rlang", "rmarkdown", "rsconnect", "rstudioapi", "stringi", "stringr", "tibble", "tidyr", "tidyselect", "tinytex", "urltools", "vegan", "xfun"))
pkgbuild::has_build_tools(debug = TRUE)
library(devtools)
devtools::install_github("rmclereath/rethinking")
devtools::install_github("rmcelreath/rethinking")
library(rethinking)
install.packages("devtools")
library(devtools)
install.packages("devtools")
library(devtools)
install.packages("rtools")
library(devtools)
install.packages("rlang")
library(rlang)
library(rlang)
library(devtools)
install.packages("backports")
library(backports)
library(devtools)
devtools::install_github("rmclereath/rethinking")
devtools::install_github("rmcelreath/rethinking")
library(rtools)
R.Version()
install.Rtools(check=T)
install.rtools(check=T)
install.rtools()
find_rtools()
find.package("devtools")
remove.packages("devtools")
install.packages("devtools")
install.packages("devtools")
library(devtools)
find_rtools()
install.packages("rtools")
find.package("rtools")
library(rtools)
library(Rtools)
find_Rtools()
library(rethinking)
data(Howell1)
head(Howell1)
precis(Howell1)
1e4
rnorm(1e4,178,20)
sample_mu <- rnorm(1e4,178,20) #creates a list of 10000 values with mean 178 and standard deviation 20
sample_sigma <- runif(1e4, 0, 50) #creates a list of 10000 values equally likely to be between 0 and 50
sample_sigma
prior_h <- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_h)
library(rethinker)
data(Howell1)
head(Howell1)
library(devtools)
data(Howell1)
library(rethinking)
data(Howell1)
sample_mu <- rnorm(1e4,178,20) #creates a list of 10000 values with mean 178 and standard deviation 20
sample_sigma <- runif(1e4, 0, 50) #creates a list of 10000 values equally likely to be between 0 and 50
prior_h <- rnorm(1e4, sample_mu, sample_sigma) #create prior distribution of height values based on simulated mu and sigma
dens(prior_h) #visualise prior distribution
precis(Howell1)
sample_mu <- rnorm(1e4,178,100) #creates a list of 10000 values with mean 178 and standard deviation 20
sample_sigma <- runif(1e4, 0, 50) #creates a list of 10000 values equally likely to be between 0 and 50
prior_h <- rnorm(1e4, sample_mu, sample_sigma) #create prior distribution of height values based on simulated mu and sigma
dens(prior_h)
install.packages("quap")
d<- Howell1
d1 <- d[d$height>=18,]
View(d1)
d$height>=18
d1 <- d[d$age>=18,]
dens(d1)
dens(d1$height)
curve(dnorm(x, 178, 20), from=100, to=250)
curve(dnorm(x, 178, 20), from=100, to=250)
curve(dunif(x, 0, 50), from=-10, to=60) #plausible standard dev values
sample_mu <- rnorm(1e4,178,20) #creates a list of 10000 values with mean 178 and standard deviation 20
sample_sigma <- runif(1e4, 0, 50) #creates a list of 10000 values equally likely to be between 0 and 50
prior_h <- rnorm(1e4, sample_mu, sample_sigma) #create prior distribution of height values based on simulated mu and sigma
dens(prior_h) #visualise prior distribution
mu.list <- seq( from=140, to=160 , length.out=200 )
sigma.list <- seq( from=4 , to=9 , length.out=200 )
post <- expand.grid( mu=mu.list , sigma=sigma.list )
post$LL <- sapply( 1:nrow(post) , function(i) sum( dnorm(
d2$height ,
mean=post$mu[i] ,
sd=post$sigma[i] ,
log=TRUE ) ) )
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE )
post$prob <- exp( post$prod - max(post$prod) )
d2 <- d[d$age>=18,]
mu.list <- seq( from=140, to=160 , length.out=200 )
sigma.list <- seq( from=4 , to=9 , length.out=200 )
post <- expand.grid( mu=mu.list , sigma=sigma.list )
post$LL <- sapply( 1:nrow(post) , function(i) sum( dnorm(
d2$height ,
mean=post$mu[i] ,
sd=post$sigma[i] ,
log=TRUE ) ) )
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) +
dunif( post$sigma , 0 , 50 , TRUE )
post$prob <- exp( post$prod - max(post$prod) )
post$prob
dens(post$prob)
contour_xyz(post$mu, post$sigma, post$prob)
image_xyz(post$mu, post$sigma, post$prob) #heat map
sample.rows <- sample( 1:nrow(post) , size=1e4 , replace=TRUE ,
prob=post$prob )
sample.mu <- post$mu[ sample.rows ]
sample.sigma <- post$sigma[ sample.rows ]
plot( sample.mu , sample.sigma , cex=0.5 , pch=16 , col=col.alpha(rangi2,0.1) )
dens( sample.mu )
dens( sample.sigma )
dens( sample.mu )
dens( sample.sigma )
HPDI(sample.mu)
HDPI(sample.sigma)
HPDI(sample.sigma)
flist <- alist (height ~ dnorm(mu sigma),
mu ~ dnorm(178, 20),
sigma ~ dunif(0,50))
flist <- alist (height ~ dnorm(mu sigma),
mu ~ dnorm(178, 20),
sigma ~ dunif(0,50))
flist <- alist (height ~ dnorm(mu, sigma),
mu ~ dnorm(178, 20),
sigma ~ dunif(0,50))
View(flist)
model <- quap(flist, data=d2)
library(rethinking)
model <- quap(flist, data=d2)
help(quap)
help(rethinking
help(rethinking)
help(rethinking)
quap(flist, data=d2)
model <- map(flist, data=d2)
precis(model)
summary(model)
post <- extract.samples(model, n=1e4)
head(post)
dens(post$sigma)
dens(post$mu)
set.seed(2971)
N <- 100 #we want to simulate 100 lines
b <- rnorm(N, 0,10)    #beta is an interaction term that describes the relationship between height and weight (slope of linear regression)
b ~ dnorm(N, 0, 10)
plot(d2$height, d2$weight)
xbar <- mean(d2$weight)
m2 <- map(
alist(
height ~ dnorm(mu, sigma),
mu <- a + b*(weight - xbar),
a ~ dnorm( 178 , 100 ) ,
b ~ dlnorm( 0 , 1 ) , #dlnorm is log normal distribution
sigma ~ dunif( 0 , 50 )
) ,
data=d2 )
summary(m2)
post <- extract.samples(m2)
a.map <- mean(post$a)
curve(a.map + b.map*(x-xbar), add=T)
b.map <- mean(post$b)
curve(a.map + b.map*(x-xbar), add=T)
install.packages('rstan')
version()
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
library(rstan)
update.packages(StanHeaders)
install.packages("StanHeaders")
library(rstan)
rstan_options(auto_write = TRUE)
Sys.setenv(LOCAL_CPPFLAGS = '-march=native')
install.packages("rethinking")
install.packages(c("coda","mvtnorm","devtools"))
install.packages(c("coda", "mvtnorm", "devtools"))
library(devtools)
install.packages("usethis")
library(devtools)
install.packages("callr")
library(devtools)
devtools::install_github("rmcelreath/rethinking")
update.packages(rethinking)
help(rethinking)
p_grid -> seq(from=0, to=1, length.out=20)
library(rethinking)
p_grid -> seq(from=0, to=1, length.out=20)
p_grid <- seq(from=0, to=1, length.out=20)
p_grid
prior <- rep(1, 20)
prior
likelihood <- dbinom(6, size=9, prob=p_grid)
posterior <- unstd.posterior/sum(unstd.posterior)
likelihood
?dbinom
plot(liklihood)
plot(likelihood)
unstd.posterior <- likelihood*prior
plot(unstd.posterior)
posterior <- unstd.posterior/sum(unstd.posterior)
plot(posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
p_grid <- seq(from=0, to=1, length.out=100) #gives you 20 values between 0 and 1
prior <- rep(1, 100) #makes a vector of 20 1's
# step 3 - compute likelihood at each value in grid
likelihood <- dbinom(6, size=9, prob=p_grid) #produces a binomial distribution
plot(likelihood)
unstd.posterior <- likelihood*prior  #in this case values don't change because prior is uniform
posterior <- unstd.posterior/sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
prior <- ifelse(p_grid <0.5, 0, 1)
p_grid <- seq(from=0, to=1, length.out=20) #gives you 20 values between 0 and 1
prior <- ifelse(p_grid <0.5, 0, 1)
likelihood <- dbinom(6, size=9, prob=p_grid) #produces a binomial distribution
unstd.posterior <- likelihood*prior  #in this case values don't change because prior is uniform
posterior <- unstd.posterior/sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
prior <- exp(-5*abs(p_grid-0.5))
plot(prior)
prior
p_grid <- seq(from=0, to=1, length.out=20) #gives you 20 values between 0 and 1
prior <- exp(-5*abs(p_grid-0.5))  # set prior so most likely values are in the middle
plot(prior)
likelihood <- dbinom(6, size=9, prob=p_grid) #produces a binomial distribution
unstd.posterior <- likelihood*prior  #in this case values don't change because prior is uniform
posterior <- unstd.posterior/sum(unstd.posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
?alist
alist(                  #alist coerces numbers into lists
w ~ dbinom(9,p) , # binomial likelihood
p ~ dunif(0,1) # uniform prior
)
dbinom(9, p)
globe.qa <- map(
alist(                  #alist coerces numbers into lists
w ~ dbinom(9,p) , # binomial likelihood
p ~ dunif(0,1) # uniform prior
) ,
data=list(w=6) )
precis(globe.qa)
?dbinom
data
list(w=6)
w <- 6
n <- 9
curve(dbeta(x, w+1, n-w+1), from=0, t=1)
curve( dbeta( x , w+1 , n-w+1 ) , from=0 , to=1 )
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE )
data(Howell1)
library(rethinking)
data(Howell1)
head(Howell1)
d<- Howell1
precis(Howell1)
sample_mu <- rnorm(1e4,178,20) #creates a list of 10000 values with mean 178 and standard deviation 20
sample_sigma <- runif(1e4, 0, 50) #creates a list of 10000 values equally likely to be between 0 and 50
prior_h <- rnorm(1e4, sample_mu, sample_sigma) #create prior distribution of height values based on simulated mu and sigma
dens(prior_h) #visualise prior distribution
PrPV <- 0.95
PrPM <- 0.01
PrV <- 0.0001
PrP <- PrPV*PrV + PrPM+(1-PrV)
(PrPV*PrV)/PrP
PrPV*PrV/PrP
PrV <- 0.001
PrP <- PrPV*PrV + PrPM+(1-PrV)
PrPV*PrV/PrP
PrP <- PrPV*PrV + PrPM*(1-PrV)
PrPV*PrV/PrP
p_grid <- seq( from=0 , to=1 , length.out=1000 )
prior <- rep( 1 , 1000 )
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)
plot(posterior)
help(sample)
samples <- sample(p_grid, prob=posterior, size=1e4, replace=T)  #argument prob gives a probability weight to every value in the vector passed in as the first argument, in this case p_grid
plot(samples)
dens(samples)
sum(posterior[p_grid<0.5])
sum(samples < 0.5)/1e4
samples <- sample(p_grid, prob=posterior, size=1e4, replace=T)  #argument prob gives a probability weight to every value in the vector passed in as the first argument, in this case p_grid
sum(samples < 0.5)/1e4
sum(sample >0.5 & samples < 0.75)/1e4
sum(sample > 0.5)/1e4
sum(samples > 0.5 & samples < 0.75)/1e4
quantile(samples, 0.8)
quantile(samples, c(0.1, 0.9))
PI(samples, prob=0.5)
HDPI(samples, prob=0.5)
HPDI(samples, prob=0.5)
p_grid[which.max(posterior)]
chainmode(sample, adj=0.01)
chainmode(samples, adj=0.01)
help(chainmode)
chainmode(samples, adj=0.1)
dbinom(0:2, size=2, prob=0.7)
rbinom(1, size=2, prob=0.7)
rbinom(10, size=2, prob=0.7) # 10 rounds of randomly...
rbinom(100, size=2, prob=0.7) # 10 rounds of randomly...
dummy_w <- rbinom(1e5, size=2, prob=0.7)
table(dummy_w)/1e5
simplehist(dummy_w)
dummy_w <- rbinom(1e5, size=9, prob=0.7)
simplehist(dummy_w)
dummy_w <- rbinom(1e5, size=9, prob=0.7)
simplehist(dummy_w)
dummy_w <- rbinom(1e5, size=50, prob=0.7)
simplehist(dummy_w)
dummy_w <- rbinom(1e5, size=9, prob=0.7)
#visualise results in a histogram
simplehist(dummy_w)
w <- rbinom(1e4, size=9, prob=0.6)
plot(w)
hist(w)
w <- rbinom(1e4, size=9, prob=0.5)
hist(w)
w <- rbinom(1e4, size=9, prob=0.8)
hist(w)
w <- rbinom(1e4, size=9, prob=samples)
hist(w)
pos <- replicate(1000, sum(runif(16,-1, 1)))
plot(density(pos))
pos <- replicate(10000, sum(runif(16,-1, 1)))
plot(density(pos))
pos <- replicate(1000000, sum(runif(16,-1, 1)))
plot(density(pos))
pos <- replicate(10, sum(runif(16,-1, 1)))
# plot distribution of final positions
plot(density(pos))
pos <- replicate(1000, sum(runif(16,-1, 1)))
runif(12,0,0.1)
data(Howell1)
str(Howell1)
df <- Howell1
library(IRkernel)
install.packages('IRkernel')
library(IRkernel)
IRkernel::installspec()
IRkernel::installspec()
install.packages("IRkernel")
library(IRkernel)
IRkernel::installspec()
library(dplyr)
library(tidyr)
library(ggplot2)
setwd('C:/Users/tmgor/Dropbox/Taylor Chapter 3/Predict_Maturity/Data/for model/out')
mat = read.csv('mat11_model_results.csv')
read.csv('mat11_predicteda50s.csv')
pa50s <- read.csv('mat11_predicteda50s.csv')
pa50s <- read.csv('mat18_predicteda50s.csv')
pss <- read.csv('mat18_predictedSs')
pss <- read.csv('mat18_predictedSs.csv')
setwd('C:/Users/tmgor/Dropbox/Taylor Chapter 3/Predict_Maturity/Data/for model/in')
obs <- read.csv('tmp_car_traits.csv')
View(pa50s)
setwd('C:/Users/tmgor/Dropbox/Taylor Chapter 3/Predict_Maturity/Data/for model/out')
og = read.csv('predicted_ogives.csv')
View(og)
pa50s <- read.csv('mat18_predicteda50s.csv')
pss <- read.csv('mat18_predictedSs.csv')
View(pss)
ggplot(birthwt, aes(x=factor(race), y=bwt)) + geom_boxplot()
library(MASS) # For the data set
ggplot(birthwt, aes(x=factor(race), y=bwt)) + geom_boxplot()
view(birthwt)
birthwt
names(pa50s)
ggplot(pa50s, aes(x=a50mu, y=species_full)) + geom_point()
ggplot(pa50s, aes(x=a505, y=species_full)) + geom_point()
ggplot(pa50s, aes(x=a50mu, y=species_full, colour=species_full)) + geom_point()
ggplot(pa50s, aes(x=a50mu, y=species_full, colour=species_full)) + geom_point() + guides(fill=FALSE)
a <- ggplot(pa50s, aes(x=a50mu, y=species_full, colour=species_full)) + geom_point()
a + guides(fill=FALSE)
a + scale_fill_discrete(guide=FALSE)
a + theme(legend.position = "none")
names(pa50s)
pa50s2 <- gather(a50, perc, a50mu, a505, a5025, a5075, a5095)
pa50s2 <- gather(pa50s, a50, a50mu, a505, a5025, a5075, a5095)
View(pa50s2)
pa50s2 <- gather(pa50s, perc, a50, a50mu, a505, a5025, a5075, a5095)
a <- ggplot(pa50s2, aes(x=a50, y=species_full, colour=species_full)) + geom_point()
a + theme(legend.position = "none")
obs
View(obs)
names(obs)
p3 <- left_join(pa50s2, obs, by=c("species_full"="ï..species_full"))
View(p3)
pa50s2 <- gather(pa50s, perc, pa50, a50mu, a505, a5025, a5075, a5095)
p3 <- left_join(pa50s2, obs, by=c("species_full"="ï..species_full"))
a <- ggplot(pa50s2, aes(x=pa50, y=species_full, colour=species_full)) + geom_point()
a + theme(legend.position = "none")
a <- ggplot(p3, aes(x=pa50, y=species_full, colour=species_full)) + geom_point()
a + theme(legend.position = "none")
b <- ggplot(p3, aes(y=species_full, colour=species_full)) + geom_point(aes(x=pa50)) + geom_point(aes(x=a50))
b + theme(legend.position = "none")
b <- ggplot(p3, aes(y=species_full)) + geom_point(aes(x=pa50, colour=species_full)) + geom_point(aes(x=a50))
b + theme(legend.position = "none")
b <- ggplot(p3, aes(y=species_full)) + geom_point(aes(x=pa50, colour=species_full, size=6)) + geom_point(aes(x=a50, size=6))
b + theme(legend.position = "none")
setwd('C:/Users/tmgor/Dropbox/Taylor Chapter 3/Predict_Maturity/Data/for model/out')
setwd('C:/Users/tmgor/Dropbox/Taylor Chapter 3/Predict_Maturity/Data/for model/out')
png('mat18_predict_a50s.png', width=1500, height=700)
b <- ggplot(p3, aes(y=species_full)) + geom_point(aes(x=pa50, colour=species_full, size=6)) + geom_point(aes(x=a50, size=6))
b + theme(legend.position = "none")
dev.off()
